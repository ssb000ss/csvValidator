#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
streaming_csv_parser

CLI-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV: –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏
—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–∞–≤–∏–ª–æ 90% –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ
–∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–ª–æ–Ω–æ–∫ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ —Å –ø–æ–ø—ã—Ç–∫–æ–π —Å–∫–ª–µ–π–∫–∏.

–ó–∞–ø—É—Å–∫:
    python streaming_csv_parser.py input.csv export.csv bad.csv [--encoding ...]

–°–º. README.md –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.
"""

import argparse
import csv
import chardet
import logging
from pathlib import Path
from typing import Generator, Tuple

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
from logging.handlers import RotatingFileHandler
from config import LOGS_DIR

logger = logging.getLogger("streaming_csv_parser")
logger.setLevel(logging.INFO)

# –°–æ–∑–¥–∞—ë–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏: —Ä–æ—Ç–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –≤ –æ–±—â–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ –ª–æ–≥–æ–≤ + –∫–æ–Ω—Å–æ–ª—å
log_file = (LOGS_DIR / 'streaming_csv_parser.log')
file_handler = RotatingFileHandler(log_file, maxBytes=5 * 1024 * 1024, backupCount=3, encoding='utf-8')
console_handler = logging.StreamHandler()

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)

# –ò–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ö—ç–Ω–¥–ª–µ—Ä–æ–≤ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∏–º–ø–æ—Ä—Ç–µ
if not logger.handlers:
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)


def detect_encoding(file_path: Path, sample_size: int = 10000) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞."""
    try:
        with open(file_path, "rb") as f:
            raw_data = f.read(sample_size)
            result = chardet.detect(raw_data)
            if result["confidence"] or 0.1 < 0.7:
                encoding = "utf-8"
            else:
                encoding = result['encoding'] or 'utf-8'
            if encoding.lower() == 'ascii':
                encoding = 'utf-8'

            logger.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∞: {encoding}")
            return encoding
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º utf-8")
        return 'utf-8'


def detect_delimiter(file_path: Path, encoding: str, max_lines: int = 30) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å CSV."""
    try:
        with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
            lines = [f.readline() for _ in range(max_lines)]
            sample = ''.join(lines)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π CSV sniffer
            sniffer = csv.Sniffer()
            try:
                dialect = sniffer.sniff(sample)
                delimiter = dialect.delimiter
                logger.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {repr(delimiter)}")
                return delimiter
            except csv.Error:
                # Fallback –Ω–∞ —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                delimiters = [',', ';', '\t', '|']
                counts = {d: sum(line.count(d) for line in lines) for d in delimiters}
                delimiter = max(counts, key=counts.get)
                logger.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (—á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑): {repr(delimiter)}")
                return delimiter
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø—è—Ç—É—é")
        return ','


def analyze_csv_stats(file_path: Path, encoding: str, max_lines: int = 10000, provided_delimiter: str | None = None):
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–µ max_lines —Å—Ç—Ä–æ–∫, –ø–æ–¥–±–∏—Ä–∞—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (delimiter, header_cols, modal_cols, total_rows, modal_share)
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    - –ö–∞–Ω–¥–∏–¥–∞—Ç—ã: –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π delimiter, –∑–∞—Ç–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç csv.Sniffer(), –∑–∞—Ç–µ–º [',',';','\t','|'].
    - –í—ã—á–∏—Å–ª—è–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫ –∏ –¥–æ–ª—é –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
    - –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –¥–æ–ª—é –≤—ã—à–µ, –∑–∞—Ç–µ–º –±–æ–ª—å—à–µ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫ (>1), –∑–∞—Ç–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫.
    - –ï—Å–ª–∏ –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–∞—é—Ç 1 –∫–æ–ª–æ–Ω–∫—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è) –∏
      –ø–æ–≤—Ç–æ—Ä–Ω–æ —Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
    """
    import io as _io
    try:
        with open(file_path, 'r', encoding=encoding, errors='ignore', newline='') as f:
            lines = []
            for _ in range(max_lines):
                line = f.readline()
                if not line:
                    break
                lines.append(line)
        if not lines:
            raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π ‚Äî –Ω–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π, –∑–∞—Ç–µ–º sniffer, –∑–∞—Ç–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        base_candidates = [',', ';', '\t', '|']
        candidates: list[str] = []
        if provided_delimiter:
            candidates.append(provided_delimiter)
        # –ü–æ–ø—Ä–æ–±—É–µ–º sniffer
        try:
            sniffed = csv.Sniffer().sniff(''.join(lines)).delimiter
            if sniffed and sniffed not in candidates:
                candidates.append(sniffed)
        except Exception:
            pass
        # –î–æ–±–∞–≤–∏–º –±–∞–∑–æ–≤—ã–µ
        for d in base_candidates:
            if d not in candidates:
                candidates.append(d)

        results = []  # (modal_share, modal_cols, modal_count, delim, header_cols, total_rows)
        freq_counts = {}  # —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π delimeter –≤ —Å—Ç—Ä–æ–∫–µ
        sample_text = ''.join(lines)
        for d in candidates:
            try:
                # –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                if lines:
                    freq_counts[d] = sum(line.count(d) for line in lines) / max(1, len(lines))
                reader = csv.reader(_io.StringIO(sample_text), delimiter=d, quoting=csv.QUOTE_MINIMAL)
                lengths = [len(row) for row in reader]
                if not lengths:
                    continue
                header_cols = lengths[0]
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                    modal_share = modal_count / max(1, len(data_lengths))
                else:
                    modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                total_rows_local = len(lengths)
                results.append((modal_share, modal_cols, modal_count, d, header_cols, total_rows_local))
            except Exception:
                continue
        if not results:
            # –§–æ–ª–±—ç–∫: –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–æ —á–∞—Å—Ç–æ—Ç–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–π –∏ –≤–µ—Ä–Ω—É—Ç—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
            try:
                if lines:
                    # –û–±–Ω–æ–≤–∏–º freq_counts –µ—Å–ª–∏ –ø—É—Å—Ç–æ–π
                    if not freq_counts:
                        for d in candidates:
                            try:
                                freq_counts[d] = sum(line.count(d) for line in lines) / max(1, len(lines))
                            except Exception:
                                freq_counts[d] = 0.0
                    # –í—ã–±–∏—Ä–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–æ—Ç–æ–π
                    best_d = max(freq_counts.items(), key=lambda kv: kv[1])[0] if freq_counts else ','
                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –µ—â—ë —Ä–∞–∑ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
                    try:
                        reader = csv.reader(_io.StringIO(sample_text), delimiter=best_d, quoting=csv.QUOTE_MINIMAL)
                        lengths = [len(row) for row in reader]
                    except Exception:
                        # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: –ø–æ split
                        lengths = [len(line.split(best_d)) for line in lines]
                    if not lengths:
                        lengths = [1]
                    header_cols = lengths[0]
                    data_lengths = lengths[1:] if len(lengths) > 1 else []
                    if data_lengths:
                        from collections import Counter
                        cnt = Counter(data_lengths)
                        modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                        modal_share = modal_count / max(1, len(data_lengths))
                    else:
                        modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                    total_rows_local = len(lengths)
                    logger.warning("‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Ñ–æ–ª–±—ç–∫")
                    return best_d, header_cols, modal_cols, total_rows_local, modal_share
                else:
                    # –í–æ–æ–±—â–µ –Ω–µ—Ç —Å—Ç—Ä–æ–∫ ‚Äî —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π
                    logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏; –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                    return ',', 0, 0, 0, 1.0
            except Exception as _e:
                # –í —Å–ª—É—á–∞–µ –ª—é–±–æ–π –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –æ—à–∏–±–∫–∏ ‚Äî –≤–µ—Ä–Ω—É—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                logger.warning(f"‚ö†Ô∏è –§–æ–ª–±—ç–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {_e}. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                return ',', 1, 1, len(lines), 1.0

        # –ï—Å–ª–∏ —Å—Ä–µ–¥–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –µ—Å—Ç—å modal_cols > 1 ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å 1 –∫–æ–ª–æ–Ω–∫–æ–π
        max_cols = max(r[1] for r in results)
        if max_cols > 1:
            filtered = [r for r in results if r[1] > 1]
        else:
            filtered = results

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ (–¥–æ–ª—è, —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ —Å –º–æ–¥–∞–ª—å–Ω—ã–º)
        filtered.sort(key=lambda r: (r[0], r[1], r[2]), reverse=True)
        best = filtered[0]

        # –ï—Å–ª–∏ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –≤—Å—ë –µ—â—ë –¥–∞—ë—Ç 1 –∫–æ–ª–æ–Ω–∫—É, –ø—Ä–∏–º–µ–Ω–∏–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Ñ–æ–ª–ª–±–µ–∫
        if best[1] == 1:
            # –í—ã–±–µ—Ä–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–æ—Ç–æ–π –≤ —Å—Ç—Ä–æ–∫–µ
            if freq_counts:
                best_d = max(freq_counts.items(), key=lambda kv: kv[1])[0]
                # –ü–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è best_d
                reader = csv.reader(_io.StringIO(sample_text), delimiter=best_d, quoting=csv.QUOTE_MINIMAL)
                lengths = [len(row) for row in reader]
                header_cols = lengths[0] if lengths else 1
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                    modal_share = modal_count / max(1, len(data_lengths))
                else:
                    modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                total_rows_local = len(lengths)
                best = (modal_share, modal_cols, modal_count, best_d, header_cols, total_rows_local)

        best_share, best_modal_cols, _best_modal_count, best_delim, best_header_cols, best_total_rows = best
        return best_delim, best_header_cols, best_modal_cols, best_total_rows, best_share
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ CSV: {e}")


def process_csv_streaming(input_path: Path, output_path: Path, bad_path: Path,
                          encoding: str, delimiter: str, export_delimiter: str = '~',
                          batch_size: int = 10000, expected_columns=None, bad_raw_path: Path | None = None):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç CSV –ø–æ—Ç–æ–∫–æ–≤–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏."""

    valid_count = 0
    bad_count = 0

    try:
        # –û–ø—Ä–µ–¥–µ–ª–∏–º –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞ —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ (–ª–∏–Ω–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        if bad_raw_path is None:
            bad_raw_path = bad_path.with_name(f"{bad_path.stem}_raw.txt")
        with open(input_path, 'r', encoding=encoding, errors='ignore', newline='') as infile, \
                open(output_path, 'w', encoding='utf-8', newline='') as outfile, \
                open(bad_path, 'w', encoding='utf-8', newline='') as badfile, \
                open(bad_raw_path, 'w', encoding='utf-8', newline='') as badraw:

            # –°–æ–∑–¥–∞–µ–º CSV reader —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º
            reader = csv.reader(infile, delimiter=delimiter, quoting=csv.QUOTE_MINIMAL)

            # –°–æ–∑–¥–∞–µ–º CSV writer —Å –Ω–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            writer = csv.writer(outfile, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)
            bad_writer = csv.writer(badfile, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ bad —Ñ–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∫–æ–ª–æ–Ω–æ–∫
            bad_header = ['–ù–æ–º–µ—Ä_—Å—Ç—Ä–æ–∫–∏', '–¢–∏–ø_–æ—à–∏–±–∫–∏', '–û–ø–∏—Å–∞–Ω–∏–µ_–æ—à–∏–±–∫–∏', '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ_—Å—Ç—Ä–æ–∫–∏']
            bad_writer.writerow(bad_header)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            try:
                header = next(reader)
                writer.writerow(header)
                header_cols = len(header)
                if expected_columns is None:
                    expected_columns_local = header_cols
                else:
                    expected_columns_local = expected_columns
                logger.info(
                    f"üìã –ó–∞–≥–æ–ª–æ–≤–æ–∫: {header_cols} —Å—Ç–æ–ª–±—Ü–æ–≤; –∏—Å–ø–æ–ª—å–∑—É–µ–º expected_columns={expected_columns_local}")
                logger.info(f"üîß –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {repr(export_delimiter)}")
            except StopIteration:
                logger.error("‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫")
                return

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ—Ç–æ–∫–æ–≤–æ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Å–∫–ª–µ–π–∫–∏ –¥–≤—É—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            import io as _io

            def _parse_row(text: str):
                try:
                    return next(csv.reader(_io.StringIO(text), delimiter=delimiter, quoting=csv.QUOTE_MINIMAL))
                except StopIteration:
                    return []
                except Exception:
                    return None

            phys_line_no = 2
            buffered_line = None
            while True:
                try:
                    if buffered_line is not None:
                        cur_line = buffered_line
                        buffered_line = None
                        from_buffer = True
                    else:
                        cur_line = infile.readline()
                        from_buffer = False
                    if not cur_line:
                        break

                    row = _parse_row(cur_line)
                    if row is not None and len(row) == expected_columns_local:
                        # –í–∞–ª–∏–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —Å—Ä–∞–∑—É –ø–∏—à–µ–º
                        writer.writerow(row)
                        valid_count += 1
                        if valid_count % batch_size == 0:
                            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {valid_count}")
                        phys_line_no += 1
                        continue

                    # –ù–µ–≤–∞–ª–∏–¥–Ω–∞—è ‚Äî –ø—Ä–æ–±—É–µ–º —Å–∫–ª–µ–∏—Ç—å —Å –æ–¥–Ω–æ–π —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–æ–π
                    next_line = infile.readline()
                    if next_line:
                        combined = cur_line.rstrip('\r\n') + next_line.lstrip('\r\n')
                        combined_row = _parse_row(combined)
                        if combined_row is not None and len(combined_row) == expected_columns_local:
                            writer.writerow(combined_row)
                            valid_count += 1
                            if valid_count % batch_size == 0:
                                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {valid_count}")
                            # –ø–æ—Ç—Ä–µ–±–∏–ª–∏ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏
                            phys_line_no += 2
                        else:
                            # –°–∫–ª–µ–π–∫–∞ –Ω–µ –ø–æ–º–æ–≥–ª–∞ ‚Äî –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ bad —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–æ–∫—É,
                            # —Å–ª–µ–¥—É—é—â—É—é –≤–µ—Ä–Ω—ë–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                            bad_len = (len(row) if row is not None else '‚Äî')
                            content = cur_line.rstrip('\r\n')
                            if content.strip() == "":
                                desc = "–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"
                            else:
                                desc = (
                                    f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {bad_len} –≤–º–µ—Å—Ç–æ {expected_columns_local}"
                                    if isinstance(bad_len,
                                                  int) else f"–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_columns_local} —Å—Ç–æ–ª–±—Ü–æ–≤)"
                                )
                            bad_writer.writerow([phys_line_no, "–û—à–∏–±–∫–∞_—Å—Ç—Ä—É–∫—Ç—É—Ä—ã", desc, content])
                            # –í —Ñ–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –ø–∏—à–µ–º —Å—Ç—Ä–æ–∫—É –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                            badraw.write(cur_line)
                            bad_count += 1
                            if bad_count % 1000 == 0:
                                logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {bad_count}")
                            phys_line_no += 1
                            buffered_line = next_line
                    else:
                        # –Ω–µ—Ç —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –∫–∞–∫ –±–∏—Ç—É—é
                        content = cur_line.rstrip('\r\n')
                        if content.strip() == "":
                            desc = "–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"
                        else:
                            bad_len = (len(row) if row is not None else '‚Äî')
                            desc = (
                                f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {bad_len} –≤–º–µ—Å—Ç–æ {expected_columns_local}"
                                if isinstance(bad_len,
                                              int) else f"–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_columns_local} —Å—Ç–æ–ª–±—Ü–æ–≤)"
                            )
                        bad_writer.writerow([phys_line_no, "–û—à–∏–±–∫–∞_—Å—Ç—Ä—É–∫—Ç—É—Ä—ã", desc, content])
                        # –í —Ñ–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –ø–∏—à–µ–º —Å—Ç—Ä–æ–∫—É –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                        badraw.write(cur_line)
                        bad_count += 1
                        if bad_count % 1000 == 0:
                            logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {bad_count}")
                        phys_line_no += 1

                except Exception as e:
                    # –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ
                    error_desc = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)[:100]}"
                    bad_writer.writerow([phys_line_no, "–û—à–∏–±–∫–∞_–æ–±—Ä–∞–±–æ—Ç–∫–∏", error_desc,
                                         (cur_line.rstrip('\r\n') if 'cur_line' in locals() else '')])
                    # –í —Ñ–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –ø–∏—à–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
                    if 'cur_line' in locals():
                        badraw.write(cur_line)
                    bad_count += 1
                    if bad_count % 1000 == 0:
                        logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {bad_count}")
                    phys_line_no += 1

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise

    logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í–∞–ª–∏–¥–Ω—ã—Ö: {valid_count}, –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {bad_count}")
    return valid_count, bad_count


def main():
    parser = argparse.ArgumentParser(description='–ü–æ—Ç–æ–∫–æ–≤—ã–π CSV –ø–∞—Ä—Å–µ—Ä –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–¥–∫–∏–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º')
    parser.add_argument('input_path', help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É')
    parser.add_argument('output_path', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ CSV')
    parser.add_argument('bad_path', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫')
    parser.add_argument('--encoding', help='–ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ (–∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)')
    parser.add_argument('--delimiter', help='–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤—Ö–æ–¥–Ω–æ–≥–æ CSV (–∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)')
    parser.add_argument('--export_delimiter', default='~', help='–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ~)')
    parser.add_argument('--sample_size', type=int, default=10000,
                        help='–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏')
    parser.add_argument('--batch_size', type=int, default=10000,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞')

    args = parser.parse_args()

    input_path = Path(args.input_path)
    output_path = Path(args.output_path)
    bad_path = Path(args.bad_path)

    if not input_path.exists():
        logger.error(f"‚ùå –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        return

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∞–π–ª–∞
        encoding = args.encoding or detect_encoding(input_path, args.sample_size)
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ –ø–µ—Ä–≤—ã–º 10000 —Å—Ç—Ä–æ–∫–∞–º —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º >1 –∫–æ–ª–æ–Ω–∫–∞
        delim, header_cols, modal_cols, total_rows, modal_share = analyze_csv_stats(
            input_path, encoding, max_lines=10000, provided_delimiter=args.delimiter
        )
        export_delimiter = args.export_delimiter

        logger.info(f"üîç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: encoding={encoding}, –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å={repr(delim)}")
        logger.info(
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–µ—Ä–≤—ã–º {total_rows} —Å—Ç—Ä–æ–∫–∞–º: header_cols={header_cols}, modal_cols={modal_cols}, modal_share={modal_share:.3f}")
        logger.info(f"üîß –í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {repr(export_delimiter)}")
        logger.info(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {input_path.stat().st_size / (1024 * 1024):.1f} MB")

        # –ü—Ä–∞–≤–∏–ª–æ 90%: –µ—Å–ª–∏ >= 0.9 —Å—Ç—Ä–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç modal_cols, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –æ—à–∏–±–∫–∏
        expected_columns = modal_cols if modal_share >= 0.9 else header_cols
        if header_cols != modal_cols and modal_share < 0.9:
            logger.warning(
                f"‚ö†Ô∏è –ó–∞–≥–æ–ª–æ–≤–æ–∫: {header_cols} –∫–æ–ª–æ–Ω–æ–∫, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏: {modal_cols} (–¥–æ–ª—è {modal_share:.2%}). –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å expected_columns={expected_columns}."
            )

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º CSV
        valid_count, bad_count = process_csv_streaming(
            input_path, output_path, bad_path, encoding, delim, export_delimiter, args.batch_size,
            expected_columns=expected_columns
        )

        # –í—ã–≤–µ–¥–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –≤ stdout –≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è UI
        try:
            print(f"__SUMMARY__ VALID={valid_count} BAD={bad_count}")
        except Exception:
            pass
        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ CSV –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    main()
