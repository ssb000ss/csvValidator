#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
app_streamlit

–í–µ–±‚Äë–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–∞ Streamlit –¥–ª—è CSV‚Äë–≤–∞–ª–∏–¥–∞—Ü–∏–∏. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É/–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
—Ñ–∞–π–ª–∞, –ø–æ–¥—Å—á—ë—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –∑–∞–ø—É—Å–∫ –≤–Ω–µ—à–Ω–µ–≥–æ CLI-—Å–∫—Ä–∏–ø—Ç–∞ (streaming_csv_parser.py)
—á–µ—Ä–µ–∑ subprocess —Å —Ä–∞–∑–±–æ—Ä–æ–º stdout –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.

–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –ø–æ –∫–∞—Ç–∞–ª–æ–≥–∞–º –∏–∑ config.py (DATA_DIR/EXPORT_DIR/BAD_DIR/LOGS_DIR).
–°–º. README.md –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π.
"""

import io
import os
import csv
import time
import sys
import shutil
import subprocess
from pathlib import Path
from typing import Tuple, Optional, List

import chardet
import streamlit as st
from datetime import datetime
import uuid
from config import EXPORT_DIR, BAD_DIR, DATA_DIR, LOGS_DIR

SAMPLE_BYTES = 100_000

def get_session_log_path() -> Path:
    if 'log_path' not in st.session_state:
        LOGS_DIR.mkdir(exist_ok=True)
        sid = st.session_state.get('_session_id') or str(uuid.uuid4())[:8]
        st.session_state['_session_id'] = sid
        fname = f"session_{sid}_{int(time.time())}.log"
        st.session_state['log_path'] = LOGS_DIR / fname
    return st.session_state['log_path']

def write_log(msg: str) -> None:
    path = get_session_log_path()
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    try:
        with path.open('a', encoding='utf-8') as f:
            f.write(f"{ts} {msg}\n")
    except Exception:
        pass


# --------- Core helpers ---------

def sanitize_filename(name: str) -> str:
    name = os.path.basename(name or "uploaded.csv")
    # Replace risky characters
    safe = ''.join(c if c.isalnum() or c in ('-', '_', '.', ' ') else '_' for c in name)
    if not safe.strip():
        safe = 'uploaded.csv'
    return safe


def save_uploaded_to_disk(uploaded_file, target_dir: Path) -> Path:
    """Save the uploaded file to target_dir streaming in chunks. Returns saved path."""
    target_dir.mkdir(parents=True, exist_ok=True)
    original_name = sanitize_filename(getattr(uploaded_file, 'name', 'uploaded.csv'))
    stem = Path(original_name).stem
    suffix = Path(original_name).suffix or '.csv'
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    out_path = target_dir / f"{stem}_{ts}{suffix}"
    try:
        uploaded_file.seek(0)
    except Exception:
        pass
    with open(out_path, 'wb') as out:
        # stream copy in chunks of 8MB
        try:
            shutil.copyfileobj(uploaded_file, out, length=8 * 1024 * 1024)
        except Exception:
            # some UploadedFile objects require reading in manual chunks
            uploaded_file.seek(0)
            while True:
                chunk = uploaded_file.read(8 * 1024 * 1024)
                if not chunk:
                    break
                out.write(chunk)
    try:
        uploaded_file.seek(0)
    except Exception:
        pass
    return out_path


def read_first_n_lines_bytes(file_like, n: int = 10000, chunk_size: int = 1024 * 1024) -> bytes:
    """Read from the beginning up to n lines from a binary file-like object and return bytes."""
    try:
        file_like.seek(0)
    except Exception:
        pass
    chunks: list[bytes] = []
    lines_seen = 0
    while True:
        chunk = file_like.read(chunk_size)
        if not chunk:
            break
        chunks.append(chunk)
        lines_seen += chunk.count(b'\n')
        if lines_seen >= n:
            break
    data = b''.join(chunks)
    # Trim to the position of the nth newline to avoid reading beyond n lines
    if lines_seen >= n:
        # find index of nth newline
        count = 0
        idx = -1
        for i, b in enumerate(data):
            if b == 0x0A:  # '\n'
                count += 1
                if count == n:
                    idx = i + 1
                    break
        if idx != -1:
            data = data[:idx]
    try:
        file_like.seek(0)
    except Exception:
        pass
    return data

def detect_encoding_and_reset(file_obj) -> str:
    pos = file_obj.tell()
    head = file_obj.read(SAMPLE_BYTES)
    if isinstance(head, str):
        # already text
        file_obj.seek(pos)
        return 'utf-8'
    enc = chardet.detect(head)["encoding"] or "utf-8"
    if enc and enc.lower() == 'ascii':
        enc = 'utf-8'
    file_obj.seek(0)
    return enc


def detect_input_delimiter(text_stream, max_lines: int = 30) -> str:
    pos = text_stream.tell()
    lines = [text_stream.readline() for _ in range(max_lines)]
    sample = ''.join(lines)
    text_stream.seek(pos)

    sniffer = csv.Sniffer()
    try:
        dialect = sniffer.sniff(sample)
        return dialect.delimiter
    except csv.Error:
        candidates = [',', ';', '\t', '|']
        counts = {d: sum(line.count(d) for line in lines) for d in candidates}
        return max(counts, key=counts.get)


def analyze_csv_stats_stream(text_stream, max_lines: int = 10000, provided_delimiter: Optional[str] = None):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–µ max_lines —Å—Ç—Ä–æ–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
    –∏ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–ª–æ–Ω–æ–∫. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (delimiter, header_cols, modal_cols, total_rows).
    –ë—Ä–æ—Å–∞–µ—Ç ValueError –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
    –£–ª—É—á—à–µ–Ω–∏—è:
    - –î–æ–±–∞–≤–ª–µ–Ω –∫–∞–Ω–¥–∏–¥–∞—Ç –∏–∑ csv.Sniffer().
    - –ï—Å–ª–∏ –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–∞—é—Ç 1 –∫–æ–ª–æ–Ω–∫—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç–æ—Ç–Ω—ã–π —Ñ–æ–ª–ª–±–µ–∫ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É —á–∏—Å–ª—É –≤—Ö–æ–∂–¥–µ–Ω–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è.
    """
    import io as _io
    pos = text_stream.tell()
    try:
        lines = []
        for _ in range(max_lines):
            line = text_stream.readline()
            if not line:
                break
            lines.append(line)
        if not lines:
            raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π ‚Äî –Ω–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

        base_candidates = [',', ';', '\t', '|']
        candidates: List[str] = []
        if provided_delimiter:
            candidates.append(provided_delimiter)
        # –ü–æ–ø—Ä–æ–±—É–µ–º sniffer –Ω–∞ —Å—ç–º–ø–ª–µ
        try:
            sniffed = csv.Sniffer().sniff(''.join(lines)).delimiter
            if sniffed and sniffed not in candidates:
                candidates.append(sniffed)
        except Exception:
            pass
        for d in base_candidates:
            if d not in candidates:
                candidates.append(d)

        best = None  # (score, delimiter, header_cols, modal_cols, total_rows, modal_count)
        freq_counts = {}
        sample_text = ''.join(lines)
        for d in candidates:
            try:
                freq_counts[d] = sum(line.count(d) for line in lines) / max(1, len(lines))
                reader = csv.reader(_io.StringIO(sample_text), delimiter=d, quoting=csv.QUOTE_MINIMAL)
                lengths = [len(row) for row in reader]
                if not lengths:
                    continue
                header_cols = lengths[0]
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                else:
                    modal_cols, modal_count = header_cols, 0
                total_rows = len(lengths)
                score = (modal_count / max(1, len(data_lengths))) if data_lengths else 1.0
                rank = (score, modal_count, modal_cols)
                if (best is None) or (rank > (best[0], best[5], best[3])):
                    best = (score, d, header_cols, modal_cols, total_rows, modal_count)
            except Exception:
                continue
        if best is None:
            d = provided_delimiter or ','
            reader = csv.reader(_io.StringIO(sample_text), delimiter=d, quoting=csv.QUOTE_MINIMAL)
            lengths = [len(row) for row in reader]
            if not lengths:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞")
            header_cols = lengths[0]
            data_lengths = lengths[1:] if len(lengths) > 1 else []
            if data_lengths:
                from collections import Counter
                cnt = Counter(data_lengths)
                modal_cols = max(cnt, key=cnt.get)
            else:
                modal_cols = header_cols
            return d, header_cols, modal_cols, len(lengths)

        score, delimiter, header_cols, modal_cols, total_rows, modal_count = best
        if modal_cols == 1 and freq_counts:
            # –§–æ–ª–ª–±–µ–∫: –≤—ã–±–µ—Ä–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–æ—Ç–æ–π
            best_d = max(freq_counts.items(), key=lambda kv: kv[1])[0]
            reader = csv.reader(_io.StringIO(sample_text), delimiter=best_d, quoting=csv.QUOTE_MINIMAL)
            lengths = [len(row) for row in reader]
            if lengths:
                header_cols = lengths[0]
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols = max(cnt, key=cnt.get)
                else:
                    modal_cols = header_cols
                total_rows = len(lengths)
                delimiter = best_d
        return delimiter, header_cols, modal_cols, total_rows
    finally:
        text_stream.seek(pos)


def process_csv_stream(
    bin_file,
    export_delimiter: str,
    input_encoding: Optional[str] = None,
    input_delimiter: Optional[str] = None,
    progress_callback=None,
) -> Tuple[io.BytesIO, io.BytesIO, io.BytesIO, int, int, int]:
    # Detect encoding
    encoding = input_encoding or detect_encoding_and_reset(bin_file)
    text_stream = io.TextIOWrapper(bin_file, encoding=encoding, errors='ignore', newline='')

    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö 10000 —Å—Ç—Ä–æ–∫: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –∏ –∫–æ–ª–æ–Ω–æ–∫
    det_delim, header_cols_stat, modal_cols_stat, stat_rows = analyze_csv_stats_stream(
        text_stream, max_lines=10000, provided_delimiter=input_delimiter
    )
    if header_cols_stat != modal_cols_stat:
        raise ValueError(
            f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ {header_cols_stat} –∫–æ–ª–æ–Ω–æ–∫, "
            f"–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ {modal_cols_stat} –Ω–∞ –ø–µ—Ä–≤—ã—Ö {stat_rows} —Å—Ç—Ä–æ–∫–∞—Ö"
        )
    # –ü–µ—Ä–µ–º–∞—Ç—ã–≤–∞–µ–º –ø–æ—Ç–æ–∫ –≤ –Ω–∞—á–∞–ª–æ –ø–µ—Ä–µ–¥ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    text_stream.seek(0)

    # Prepare writers
    clean_buf = io.StringIO()
    bad_buf = io.StringIO()
    bad_raw_buf = io.StringIO()

    clean_writer = csv.writer(clean_buf, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)
    bad_writer = csv.writer(bad_buf, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)

    # Bad header
    bad_writer.writerow(["–ù–æ–º–µ—Ä_—Å—Ç—Ä–æ–∫–∏", "–¢–∏–ø_–æ—à–∏–±–∫–∏", "–û–ø–∏—Å–∞–Ω–∏–µ_–æ—à–∏–±–∫–∏", "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ_—Å—Ç—Ä–æ–∫–∏"])

    reader = csv.reader(text_stream, delimiter=det_delim, quoting=csv.QUOTE_MINIMAL)

    valid_count = 0
    bad_count = 0
    total_count = 0

    # –ß–∏—Ç–∞–µ–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    try:
        header = next(reader)
        expected_columns = len(header)
        clean_writer.writerow(header)
        total_count += 1
    except StopIteration:
        # –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        clean_bytes = io.BytesIO(clean_buf.getvalue().encode('utf-8'))
        bad_bytes = io.BytesIO(bad_buf.getvalue().encode('utf-8'))
        bad_raw_bytes = io.BytesIO(bad_raw_buf.getvalue().encode('utf-8'))
        return clean_bytes, bad_bytes, bad_raw_bytes, valid_count, bad_count, total_count

    # –ü–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Å–∫–ª–µ–π–∫–∏ 2 —Å—Ç—Ä–æ–∫
    import io as _io

    def _parse_row(text: str) -> Optional[List[str]]:
        try:
            r = next(csv.reader(_io.StringIO(text), delimiter=det_delim, quoting=csv.QUOTE_MINIMAL))
            return r
        except StopIteration:
            return []
        except Exception:
            return None

    # –ù–æ–º–µ—Ä —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä–æ–∫–∏ (–ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Å 2)
    phys_line_no = 2
    buffered_line = None  # —Å—é–¥–∞ –∫–ª–∞–¥—ë–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —Å–∫–ª–µ–π–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å
    while True:
        # –ë–µ—Ä—ë–º —Å—Ç—Ä–æ–∫—É –∏–∑ –±—É—Ñ–µ—Ä–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å, –∏–Ω–∞—á–µ —á–∏—Ç–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞
        if buffered_line is not None:
            cur_line = buffered_line
            buffered_line = None
            from_buffer = True
        else:
            cur_line = text_stream.readline()
            from_buffer = False
        if not cur_line:
            break
        if not from_buffer:
            total_count += 1  # —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏

        row = _parse_row(cur_line)
        if row is not None and len(row) == expected_columns:
            # –í–∞–ª–∏–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —Å—Ä–∞–∑—É –∑–∞–ø–∏—Å—ã–≤–∞–µ–º
            clean_writer.writerow(row)
            valid_count += 1
            phys_line_no += 1
        else:
            # –ù–µ–≤–∞–ª–∏–¥–Ω–∞—è ‚Äî –ø—Ä–æ–±—É–µ–º —Å–∫–ª–µ–∏—Ç—å —Ä–æ–≤–Ω–æ —Å –æ–¥–Ω–æ–π —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–æ–π
            next_line = text_stream.readline()
            if next_line:
                total_count += 1
                combined = cur_line.rstrip('\r\n') + next_line.lstrip('\r\n')
                combined_row = _parse_row(combined)
                if combined_row is not None and len(combined_row) == expected_columns:
                    # –°–∫–ª–µ–π–∫–∞ —É–¥–∞–ª–∞—Å—å ‚Äî —Å—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é –∏ –ø–æ—Ç—Ä–µ–±–ª—è–µ–º –æ–±–µ —Å—Ç—Ä–æ–∫–∏
                    clean_writer.writerow(combined_row)
                    valid_count += 1
                    phys_line_no += 2
                else:
                    # –°–∫–ª–µ–π–∫–∞ –Ω–µ –ø–æ–º–æ–≥–ª–∞ ‚Äî —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–æ–∫—É —Å—á–∏—Ç–∞–µ–º –±–∏—Ç–æ–π,
                    # –∞ —Å–ª–µ–¥—É—é—â—É—é –≤–µ—Ä–Ω—ë–º –≤ –±—É—Ñ–µ—Ä –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    bad_len = (len(row) if row is not None else '‚Äî')
                    content = cur_line.rstrip('\r\n')
                    if content.strip() == "":
                        desc = "–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"
                    elif bad_len == '‚Äî':
                        desc = f"–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_columns} —Å—Ç–æ–ª–±—Ü–æ–≤)"
                    elif bad_len < expected_columns:
                        desc = f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {bad_len} –≤–º–µ—Å—Ç–æ {expected_columns}"
                    else:
                        desc = f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {bad_len} –≤–º–µ—Å—Ç–æ {expected_columns}"
                    bad_writer.writerow([phys_line_no, "–û—à–∏–±–∫–∞_—Å—Ç—Ä—É–∫—Ç—É—Ä—ã", desc, content])
                    # –í —Ñ–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –ø–∏—à–µ–º —Å—Ç—Ä–æ–∫—É –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                    bad_raw_buf.write(cur_line)
                    bad_count += 1
                    phys_line_no += 1
                    buffered_line = next_line  # –≤–µ—Ä–Ω—ë–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            else:
                # –ù–µ—Ç —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∫–∞–∫ –±–∏—Ç—É—é —Ç–µ–∫—É—â—É—é
                content = cur_line.rstrip('\r\n')
                if content.strip() == "":
                    desc = "–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞"
                else:
                    bad_len = (len(row) if row is not None else '‚Äî')
                    desc = (
                        f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {bad_len} –≤–º–µ—Å—Ç–æ {expected_columns}"
                        if isinstance(bad_len, int) else f"–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_columns} —Å—Ç–æ–ª–±—Ü–æ–≤)"
                    )
                bad_writer.writerow([phys_line_no, "–û—à–∏–±–∫–∞_—Å—Ç—Ä—É–∫—Ç—É—Ä—ã", desc, content])
                # –í —Ñ–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –ø–∏—à–µ–º —Å—Ç—Ä–æ–∫—É –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                bad_raw_buf.write(cur_line)
                bad_count += 1
                phys_line_no += 1

        if progress_callback and (valid_count + bad_count) % 5000 == 0:
            progress_callback(valid_count, bad_count, total_count)

    clean_bytes = io.BytesIO(clean_buf.getvalue().encode('utf-8'))
    bad_bytes = io.BytesIO(bad_buf.getvalue().encode('utf-8'))
    bad_raw_bytes = io.BytesIO(bad_raw_buf.getvalue().encode('utf-8'))
    return clean_bytes, bad_bytes, bad_raw_bytes, valid_count, bad_count, total_count


def preview_first_rows(bin_bytes: bytes, encoding: Optional[str] = None, delimiter: Optional[str] = None,
                       limit: int = 200) -> Tuple[List[str], List[List[str]], str, str]:
    """Return header, rows, detected_encoding, detected_delimiter for preview."""
    bio = io.BytesIO(bin_bytes)
    enc = encoding or detect_encoding_and_reset(bio)
    text_stream = io.TextIOWrapper(bio, encoding=enc, errors='ignore', newline='')
    delim = delimiter or detect_input_delimiter(text_stream)

    reader = csv.reader(text_stream, delimiter=delim, quoting=csv.QUOTE_MINIMAL)
    try:
        header = next(reader)
    except StopIteration:
        return [], [], enc, delim

    rows: List[List[str]] = []
    for i, row in enumerate(reader, start=1):
        rows.append(row)
        if i >= limit:
            break
    return header, rows, enc, delim


def read_log_tail(path: Path, max_lines: int = 500) -> str:
    if not path.exists():
        return "–õ–æ–≥-—Ñ–∞–π–ª –ø–æ–∫–∞ –Ω–µ —Å–æ–∑–¥–∞–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–ª–∏ —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ—è–≤–ª–µ–Ω–∏—è –ª–æ–≥–æ–≤."
    try:
        with path.open('r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        return ''.join(lines[-max_lines:])
    except Exception as e:
        return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–≥–∏: {e}"


def count_total_lines(path: Path, chunk_size: int = 8 * 1024 * 1024) -> int:
    """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ –ø–æ—Ç–æ—á–Ω–æ (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ø–∞–º—è—Ç—å)."""
    try:
        total = 0
        with open(path, 'rb') as f:
            while True:
                chunk = f.read(chunk_size)
                if not chunk:
                    break
                total += chunk.count(b'\n')
        return total
    except Exception:
        return 0


# --------- UI ---------
st.set_page_config(page_title="csvValidator", page_icon="üßπ", layout="wide")
st.title("csvValidator ‚Äî –ø—Ä–æ—Å—Ç–æ –∏ –Ω–∞–¥—ë–∂–Ω–æ")

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫—Ä—ã—Ç—ã: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
export_delim = "~"

# –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: –ª–∏–±–æ —Ñ–∞–π–ª —É–∂–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (–ø–∞–ø–∫–∞ data/), –ª–∏–±–æ –∑–∞–≥—Ä—É–∑–∫–∞
server_path = None
try:
    server_files = sorted(list(DATA_DIR.glob("*.csv")) + list(DATA_DIR.glob("*.txt")))
except Exception:
    server_files = []
options = ["‚Äî"] + [p.name for p in server_files]
chosen = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ data/", options, index=0)
if chosen != "‚Äî":
    server_path = (DATA_DIR / chosen)

# Tabs for workflow
process_tab, preview_tab, logs_tab = st.tabs(["–û–±—Ä–∞–±–æ—Ç–∫–∞", "–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö", "–õ–æ–≥–∏"])

with preview_tab:
    if server_path is None:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ data/, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫")
    else:
        # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à–æ–π —Å—ç–º–ø–ª –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞, –Ω–µ –≤–µ—Å—å —Ñ–∞–π–ª
        try:
            with open(server_path, 'rb') as f:
                sample_bytes = f.read(SAMPLE_BYTES)
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")
            sample_bytes = b""
        hdr, rows, det_enc, det_delim = preview_first_rows(
            sample_bytes,
            limit=200,
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–µ—Ä–≤—ã–º 10 000 —Å—Ç—Ä–æ–∫–∞–º: –∫–æ–ª–æ–Ω–æ–∫ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –∏ –º–æ–¥–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫
        try:
            with open(server_path, 'rb') as f:
                first_10k = read_first_n_lines_bytes(f, n=10000)
            _bio = io.BytesIO(first_10k)
            _enc = detect_encoding_and_reset(_bio)
            _bio.seek(0)
            _ts = io.TextIOWrapper(_bio, encoding=_enc, errors='ignore', newline='')
            _det_delim, _header_cols_stat, _modal_cols_stat, _stat_rows = analyze_csv_stats_stream(
                _ts, max_lines=10000, provided_delimiter=None
            )
        except Exception as _e:
            _header_cols_stat, _modal_cols_stat = (len(hdr) if hdr else 0), (len(hdr) if hdr else 0)

        colA, colB, colC = st.columns(3)
        with colA:
            st.metric("–û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞", det_enc or "‚Äî")
        with colB:
            st.metric("–û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å", repr(det_delim) if det_delim else "‚Äî")
        with colC:
            st.metric("–ö–æ–ª–æ–Ω–æ–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É", (len(hdr) if hdr else _header_cols_stat))

        colD, _ = st.columns([1, 2])
        with colD:
            st.metric("–ö–æ–ª–æ–Ω–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏", _modal_cols_stat)

        if hdr:
            st.caption("–ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞")
            # Show as a simple table without extra dependencies
            st.dataframe([dict(zip(hdr, r + [None] * (len(hdr) - len(r)))) for r in rows], use_container_width=True)
        else:
            st.warning("–§–∞–π–ª –ø—É—Å—Ç–æ–π ‚Äî –Ω–µ—á–µ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å")

with process_tab:
    if server_path is None:
        st.caption("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏‚Ä¶")
    else:
        st.info("–ù–∞–∂–º–∏—Ç–µ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ—á–∏—Å—Ç–∫—É –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é")
        if st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å", type="primary"):
            prog = st.progress(0, text="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞...")
            status = st.empty()

            write_log("–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ (CLI)")
            write_log(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: export_delimiter={repr(export_delim)}, encoding=auto, delimiter=auto")

            try:
                # 1) –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ data/
                input_path = server_path
                status.write(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: {input_path}")
                write_log(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: {input_path}")

                # 2) –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                stem = Path(input_path).stem
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                export_path = EXPORT_DIR / f"{stem}_clean_{ts}.csv"
                bad_path = BAD_DIR / f"{stem}_bad_{ts}.csv"
                bad_raw_path = BAD_DIR / f"{stem}_bad_{ts}_raw.txt"  # –≥–µ–Ω–µ—Ä–∏—Ç—Å—è —Å–∫—Ä–∏–ø—Ç–æ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

                # 3) –ó–∞–ø—É—Å–∫–∞–µ–º –≤–Ω–µ—à–Ω–∏–π —Å–∫—Ä–∏–ø—Ç –Ω–∞ –≤–µ—Å—å —Ñ–∞–π–ª (—Å –ø–æ—Ç–æ–∫–æ–≤—ã–º —á—Ç–µ–Ω–∏–µ–º stdout)
                script_path = Path(__file__).resolve().parent / "streaming_csv_parser.py"
                cmd = [
                    sys.executable,
                    str(script_path),
                    str(input_path),
                    str(export_path),
                    str(bad_path),
                    "--export_delimiter", export_delim,
                ]
                write_log(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")

                # –û—Ü–µ–Ω–∏–º —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞ (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
                status.write("–ü–æ–¥—Å—á—ë—Ç —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞‚Ä¶")
                total_lines = count_total_lines(input_path)
                total_no_header = max(0, total_lines - 1)
                prog.progress(0.0, text=f"–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏‚Ä¶ 0/{(total_no_header or '‚Äî')}")

                # –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –¥–ª—è –∂–∏–≤—ã—Ö –ª–æ–≥–æ–≤ –ø—Ä–æ—Ü–µ—Å—Å–∞
                live_logs = st.empty()
                tail: list[str] = []

                # –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å –ø–æ—Å—Ç—Ä–æ—á–Ω—ã–º —á—Ç–µ–Ω–∏–µ–º stdout
                t0 = time.time()
                with subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1,
                    universal_newlines=True,
                ) as proc:
                    status.write("–ò–¥—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞, –ª–æ–≥–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏‚Ä¶")
                    valid_seen = 0
                    bad_seen = 0
                    valid_rows = None
                    bad_rows = None

                    assert proc.stdout is not None
                    for raw_line in proc.stdout:
                        line = raw_line.rstrip("\n")
                        if not line:
                            continue
                        # –ü–∏—à–µ–º –≤ –ª–æ–≥ —Å–µ—Å—Å–∏–∏
                        write_log(line)
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç –ª–æ–≥–æ–≤ –≤ UI
                        tail.append(line)
                        if len(tail) > 200:
                            tail = tail[-200:]
                        live_logs.text_area("–ü—Ä–æ–≥—Ä–µ—Å—Å –∏ –ª–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞", value="\n".join(tail), height=240)

                        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        try:
                            if "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫:" in line:
                                # —Ñ–æ—Ä–º–∞—Ç: ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: 10000
                                num = int(''.join(ch for ch in line.split(':')[-1] if ch.isdigit()))
                                valid_seen = max(valid_seen, num)
                            elif "–ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫:" in line:
                                num = int(''.join(ch for ch in line.split(':')[-1] if ch.isdigit()))
                                bad_seen = max(bad_seen, num)
                            elif line.strip().startswith("__SUMMARY__"):
                                parts = dict(p.split('=') for p in line.strip().split()[1:])
                                valid_rows = int(parts.get('VALID')) if 'VALID' in parts else None
                                bad_rows = int(parts.get('BAD')) if 'BAD' in parts else None
                        except Exception:
                            pass

                        processed = valid_seen + bad_seen
                        if total_no_header > 0:
                            frac = min(processed / total_no_header, 0.99)
                            prog.progress(frac, text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶ {processed:,}/{total_no_header:,}".replace(',', ' '))
                        else:
                            # –ù–µ–∏–∑–≤–µ—Å—Ç–µ–Ω –æ–±—â–∏–π –æ–±—ä—ë–º ‚Äî –∏–º–∏—Ç–∏—Ä—É–µ–º –ø–ª–∞–≤–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
                            base = (processed % 100) / 100.0
                            prog.progress(base, text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed:,} —Å—Ç—Ä–æ–∫".replace(',', ' '))

                    ret = proc.wait()
                    dt = time.time() - t0

                if ret != 0:
                    prog.progress(0.0, text="–°–±–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    err_msg = "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∫—Ä–∏–ø—Ç–æ–º. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ."
                    status.write(err_msg)
                    write_log(err_msg)
                    st.error(err_msg)
                else:
                    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å–≤–æ–¥–∫–∞
                    prog.progress(1.0, text="–ì–æ—Ç–æ–≤–æ")

                    # –ï—Å–ª–∏ —Å–≤–æ–¥–∫–∞ –Ω–µ –ø—Ä–∏—à–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    if valid_rows is None:
                        valid_rows = valid_seen
                    if bad_rows is None:
                        bad_rows = bad_seen

                    summary_msg = f"–ì–æ—Ç–æ–≤–æ –∑–∞ {dt:.2f} —Å–µ–∫. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∞ –¥–∏—Å–∫."
                    if (valid_rows is not None) and (bad_rows is not None):
                        total_rows = valid_rows + bad_rows
                        summary_msg += f" –ò—Ç–æ–≥: –≤–∞–ª–∏–¥–Ω—ã—Ö={valid_rows}, –æ—à–∏–±–æ–∫={bad_rows}, –≤—Å–µ–≥–æ(–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)={total_rows}."
                        write_log(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: VALID={valid_rows}, BAD={bad_rows}, TOTAL(no header)={total_rows}")
                    status.write(summary_msg)
                    write_log(summary_msg)
                    saved_msg = f"–§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: clean ‚Üí {export_path}, bad ‚Üí {bad_path}, bad_raw ‚Üí {bad_raw_path}"
                    st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    st.caption(saved_msg)

                    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ‚Äî –ø–æ–∫–∞–∂–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    if (valid_rows is not None) and (bad_rows is not None):
                        m1, m2, m3 = st.columns(3)
                        with m1:
                            st.metric("–í–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫", f"{valid_rows:,}".replace(",", " "))
                        with m2:
                            st.metric("–û—à–∏–±–æ–∫", f"{bad_rows:,}".replace(",", " "))
                        with m3:
                            st.metric("–í—Å–µ–≥–æ (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)", f"{(valid_rows + bad_rows):,}".replace(",", " "))

                    # 4) –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–µ–≤—å—é (–ø–µ—Ä–≤—ã–µ 10 000 —Å—Ç—Ä–æ–∫), —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –≤–µ—Å—å —Ñ–∞–π–ª –≤ –û–ó–£
                    preview_limit = 10000

                    def _first_n_lines_bytes(path: Path, n: int = 10000) -> bytes:
                        try:
                            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                                lines = []
                                for i, line in enumerate(f, start=1):
                                    lines.append(line)
                                    if i >= n:
                                        break
                            return ''.join(lines).encode('utf-8')
                        except Exception as e:
                            return f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–≤—å—é: {e}\n".encode('utf-8')

                    col1, col2, col3 = st.columns(3)
                    try:
                        with col1:
                            st.download_button(
                                f"–°–∫–∞—á–∞—Ç—å –ø—Ä–µ–≤—å—é –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ CSV (–ø–µ—Ä–≤—ã–µ {preview_limit:,} —Å—Ç—Ä–æ–∫)".replace(',', ' '),
                                data=_first_n_lines_bytes(export_path, preview_limit),
                                file_name=f"preview_{export_path.name}",
                                mime="text/csv; charset=utf-8",
                            )
                        with col2:
                            st.download_button(
                                f"–°–∫–∞—á–∞—Ç—å –ø—Ä–µ–≤—å—é –æ—à–∏–±–æ–∫ (–ø–µ—Ä–≤—ã–µ {preview_limit:,} —Å—Ç—Ä–æ–∫)".replace(',', ' '),
                                data=_first_n_lines_bytes(bad_path, preview_limit),
                                file_name=f"preview_{bad_path.name}",
                                mime="text/csv; charset=utf-8",
                            )
                        with col3:
                            if bad_raw_path.exists():
                                st.download_button(
                                    f"–°–∫–∞—á–∞—Ç—å –ø—Ä–µ–≤—å—é —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ (–ø–µ—Ä–≤—ã–µ {preview_limit:,} —Å—Ç—Ä–æ–∫)".replace(',', ' '),
                                    data=_first_n_lines_bytes(bad_raw_path, preview_limit),
                                    file_name=f"preview_{bad_raw_path.name}",
                                    mime="text/plain; charset=utf-8",
                                )
                            else:
                                st.caption("–§–∞–π–ª —Å—ã—Ä—ã—Ö –æ—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –æ—à–∏–±–æ–∫)")

                        st.info(
                            "–ü–æ–ª–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∞ –¥–∏—Å–∫ –∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤ –ø–∞–º—è—Ç—å: "
                            f"clean ‚Üí {export_path}, bad ‚Üí {bad_path}, bad_raw ‚Üí {bad_raw_path if bad_raw_path.exists() else '‚Äî'}.\n"
                            "–°–∫–∞—á–∞–π—Ç–µ –∏—Ö –Ω–∞–ø—Ä—è–º—É—é —Å —Å–µ—Ä–≤–µ—Ä–∞/–¥–∏—Å–∫–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω—ã —Ü–µ–ª–∏–∫–æ–º."
                        )
                    except Exception as save_err:
                        msg = f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–µ–≤—å—é –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {save_err}"
                        status.write(msg)
                        write_log(msg)
            except Exception as e:
                prog.progress(0.0)
                err = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}"
                status.write(err)
                write_log(err)
                st.error(err)

with logs_tab:
    log_file = get_session_log_path()
    st.caption(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–æ–≤ –¥–ª—è –≤–∞—à–µ–π —Å–µ—Å—Å–∏–∏: {log_file}")
    auto = st.checkbox("–ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥", value=True, key="logs_auto")
    log_text = read_log_tail(log_file, max_lines=500)
    st.text_area("–õ–æ–≥–∏", value=log_text, height=300)
    if auto:
        time.sleep(5)
        st.rerun()
