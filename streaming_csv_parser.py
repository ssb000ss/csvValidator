#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
streaming_csv_parser

CLI-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ CSV: Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¸
Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»Ñ, ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹, Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ 90% Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾
ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑÑ‚Ñ€Ğ¾Ğº Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¾Ğ¹ ÑĞºĞ»ĞµĞ¹ĞºĞ¸.

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python streaming_csv_parser.py input.csv export.csv bad.csv [--encoding ...]

Ğ¡Ğ¼. README.md Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹.
"""

import argparse
import csv
import chardet
import logging
from pathlib import Path
from typing import Generator, Tuple

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ°
from logging.handlers import RotatingFileHandler
from config import LOGS_DIR

logger = logging.getLogger("streaming_csv_parser")
logger.setLevel(logging.INFO)

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸: Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² Ğ¾Ğ±Ñ‰ĞµĞ¼ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğµ Ğ»Ğ¾Ğ³Ğ¾Ğ² + ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ
log_file = (LOGS_DIR / 'streaming_csv_parser.log')
file_handler = RotatingFileHandler(log_file, maxBytes=5 * 1024 * 1024, backupCount=3, encoding='utf-8')
console_handler = logging.StreamHandler()

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)

# Ğ˜Ğ·Ğ±ĞµĞ¶Ğ°Ñ‚ÑŒ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ…ÑĞ½Ğ´Ğ»ĞµÑ€Ğ¾Ğ² Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğµ
if not logger.handlers:
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)


def detect_encoding(file_path: Path, sample_size: int = 10000) -> str:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ Ñ„Ğ°Ğ¹Ğ»Ğ°."""
    try:
        with open(file_path, "rb") as f:
            raw_data = f.read(sample_size)
            result = chardet.detect(raw_data)
            encoding = result['encoding'] or 'utf-8'

            if encoding.lower() == 'ascii':
                encoding = 'utf-8'

            logger.info(f"âœ… ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ° ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°: {encoding}")
            return encoding
    except Exception as e:
        logger.warning(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸: {e}. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ utf-8")
        return 'utf-8'


def detect_delimiter(file_path: Path, encoding: str, max_lines: int = 30) -> str:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ CSV."""
    try:
        with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
            lines = [f.readline() for _ in range(max_lines)]
            sample = ''.join(lines)

            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ CSV sniffer
            sniffer = csv.Sniffer()
            try:
                dialect = sniffer.sniff(sample)
                delimiter = dialect.delimiter
                logger.info(f"âœ… ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ: {repr(delimiter)}")
                return delimiter
            except csv.Error:
                # Fallback Ğ½Ğ° Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
                delimiters = [',', ';', '\t', '|']
                counts = {d: sum(line.count(d) for line in lines) for d in delimiters}
                delimiter = max(counts, key=counts.get)
                logger.info(f"âœ… ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ (Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·): {repr(delimiter)}")
                return delimiter
    except Exception as e:
        logger.warning(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»Ñ: {e}. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ¿ÑÑ‚ÑƒÑ")
        return ','


def analyze_csv_stats(file_path: Path, encoding: str, max_lines: int = 10000, provided_delimiter: str | None = None):
    """
    Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ max_lines ÑÑ‚Ñ€Ğ¾Ğº, Ğ¿Ğ¾Ğ´Ğ±Ğ¸Ñ€Ğ°Ñ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: (delimiter, header_cols, modal_cols, total_rows, modal_share)
    ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼:
    - ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ñ‹: Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ delimiter, Ğ·Ğ°Ñ‚ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ csv.Sniffer(), Ğ·Ğ°Ñ‚ĞµĞ¼ [',',';','\t','|'].
    - Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº Ğ¸ Ğ´Ğ¾Ğ»Ñ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ°.
    - ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ´Ğ¾Ğ»Ñ Ğ²Ñ‹ÑˆĞµ, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞµ Ñ‡Ğ¸ÑĞ»Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº (>1), Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº.
    - Ğ•ÑĞ»Ğ¸ Ğ²ÑĞµ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ñ‹ Ğ´Ğ°ÑÑ‚ 1 ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»Ñ) Ğ¸
      Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ°.
    """
    import io as _io
    try:
        with open(file_path, 'r', encoding=encoding, errors='ignore', newline='') as f:
            lines = []
            for _ in range(max_lines):
                line = f.readline()
                if not line:
                    break
                lines.append(line)
        if not lines:
            raise ValueError("Ğ¤Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ â€” Ğ½ĞµÑ‚ ÑÑ‚Ñ€Ğ¾Ğº Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°")

        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²: Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹, Ğ·Ğ°Ñ‚ĞµĞ¼ sniffer, Ğ·Ğ°Ñ‚ĞµĞ¼ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ
        base_candidates = [',', ';', '\t', '|']
        candidates: list[str] = []
        if provided_delimiter:
            candidates.append(provided_delimiter)
        # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ sniffer
        try:
            sniffed = csv.Sniffer().sniff(''.join(lines)).delimiter
            if sniffed and sniffed not in candidates:
                candidates.append(sniffed)
        except Exception:
            pass
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ
        for d in base_candidates:
            if d not in candidates:
                candidates.append(d)

        results = []  # (modal_share, modal_cols, modal_count, delim, header_cols, total_rows)
        freq_counts = {}  # ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ delimeter Ğ² ÑÑ‚Ñ€Ğ¾ĞºĞµ
        sample_text = ''.join(lines)
        for d in candidates:
            try:
                # Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğµ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
                if lines:
                    freq_counts[d] = sum(line.count(d) for line in lines) / max(1, len(lines))
                reader = csv.reader(_io.StringIO(sample_text), delimiter=d, quoting=csv.QUOTE_MINIMAL)
                lengths = [len(row) for row in reader]
                if not lengths:
                    continue
                header_cols = lengths[0]
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                    modal_share = modal_count / max(1, len(data_lengths))
                else:
                    modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                total_rows_local = len(lengths)
                results.append((modal_share, modal_cols, modal_count, d, header_cols, total_rows_local))
            except Exception:
                continue
        if not results:
            # Ğ¤Ğ¾Ğ»Ğ±ÑĞº: Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ¿Ğ¾ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğµ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¾Ñ†ĞµĞ½ĞºĞ¸
            try:
                if lines:
                    # ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ğ¼ freq_counts ĞµÑĞ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
                    if not freq_counts:
                        for d in candidates:
                            try:
                                freq_counts[d] = sum(line.count(d) for line in lines) / max(1, len(lines))
                            except Exception:
                                freq_counts[d] = 0.0
                    # Ğ’Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ€ĞµĞ´Ğ½ĞµĞ¹ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ¾Ğ¹
                    best_d = max(freq_counts.items(), key=lambda kv: kv[1])[0] if freq_counts else ','
                    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ· Ğ°ĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ¾
                    try:
                        reader = csv.reader(_io.StringIO(sample_text), delimiter=best_d, quoting=csv.QUOTE_MINIMAL)
                        lengths = [len(row) for row in reader]
                    except Exception:
                        # Ğ“Ñ€ÑƒĞ±Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ°: Ğ¿Ğ¾ split
                        lengths = [len(line.split(best_d)) for line in lines]
                    if not lengths:
                        lengths = [1]
                    header_cols = lengths[0]
                    data_lengths = lengths[1:] if len(lengths) > 1 else []
                    if data_lengths:
                        from collections import Counter
                        cnt = Counter(data_lengths)
                        modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                        modal_share = modal_count / max(1, len(data_lengths))
                    else:
                        modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                    total_rows_local = len(lengths)
                    logger.warning("âš ï¸ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ° ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¼ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ¼, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ğ»Ğ±ÑĞº")
                    return best_d, header_cols, modal_cols, total_rows_local, modal_share
                else:
                    # Ğ’Ğ¾Ğ¾Ğ±Ñ‰Ğµ Ğ½ĞµÑ‚ ÑÑ‚Ñ€Ğ¾Ğº â€” Ñ„Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
                    logger.warning("âš ï¸ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸; Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ")
                    return ',', 0, 0, 0, 1.0
            except Exception as _e:
                # Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ»ÑĞ±Ğ¾Ğ¹ Ğ½ĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ â€” Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
                logger.warning(f"âš ï¸ Ğ¤Ğ¾Ğ»Ğ±ÑĞº ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ»ÑÑ Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¾Ğ¹: {_e}. Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ")
                return ',', 1, 1, len(lines), 1.0

        # Ğ•ÑĞ»Ğ¸ ÑÑ€ĞµĞ´Ğ¸ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² ĞµÑÑ‚ÑŒ modal_cols > 1 â€” Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹ Ñ 1 ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¾Ğ¹
        max_cols = max(r[1] for r in results)
        if max_cols > 1:
            filtered = [r for r in results if r[1] > 1]
        else:
            filtered = results

        # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ (Ğ´Ğ¾Ğ»Ñ, Ñ‡Ğ¸ÑĞ»Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº, ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº Ñ Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼)
        filtered.sort(key=lambda r: (r[0], r[1], r[2]), reverse=True)
        best = filtered[0]

        # Ğ•ÑĞ»Ğ¸ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ğ²ÑÑ‘ ĞµÑ‰Ñ‘ Ğ´Ğ°Ñ‘Ñ‚ 1 ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ, Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ¼ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ğ»Ğ»Ğ±ĞµĞº
        if best[1] == 1:
            # Ğ’Ñ‹Ğ±ĞµÑ€ĞµĞ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ¹ ÑÑ€ĞµĞ´Ğ½ĞµĞ¹ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ¾Ğ¹ Ğ² ÑÑ‚Ñ€Ğ¾ĞºĞµ
            if freq_counts:
                best_d = max(freq_counts.items(), key=lambda kv: kv[1])[0]
                # ĞŸĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ´Ğ»Ñ best_d
                reader = csv.reader(_io.StringIO(sample_text), delimiter=best_d, quoting=csv.QUOTE_MINIMAL)
                lengths = [len(row) for row in reader]
                header_cols = lengths[0] if lengths else 1
                data_lengths = lengths[1:] if len(lengths) > 1 else []
                if data_lengths:
                    from collections import Counter
                    cnt = Counter(data_lengths)
                    modal_cols, modal_count = max(cnt.items(), key=lambda kv: (kv[1], kv[0]))
                    modal_share = modal_count / max(1, len(data_lengths))
                else:
                    modal_cols, modal_count, modal_share = header_cols, 0, 1.0
                total_rows_local = len(lengths)
                best = (modal_share, modal_cols, modal_count, best_d, header_cols, total_rows_local)

        best_share, best_modal_cols, _best_modal_count, best_delim, best_header_cols, best_total_rows = best
        return best_delim, best_header_cols, best_modal_cols, best_total_rows, best_share
    except Exception as e:
        raise ValueError(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° CSV: {e}")


def process_csv_streaming(input_path: Path, output_path: Path, bad_path: Path,
                          encoding: str, delimiter: str, export_delimiter: str = '~',
                          batch_size: int = 10000, expected_columns=None, bad_raw_path: Path | None = None):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ CSV Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸."""

    valid_count = 0
    bad_count = 0

    try:
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ Ğ¿ÑƒÑ‚ÑŒ Ğ´Ğ»Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° ÑÑ‹Ñ€Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº (Ğ»Ğ¸Ğ½Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        if bad_raw_path is None:
            bad_raw_path = bad_path.with_name(f"{bad_path.stem}_raw.txt")
        with open(input_path, 'r', encoding=encoding, errors='ignore', newline='') as infile, \
                open(output_path, 'w', encoding='utf-8', newline='') as outfile, \
                open(bad_path, 'w', encoding='utf-8', newline='') as badfile, \
                open(bad_raw_path, 'w', encoding='utf-8', newline='') as badraw:

            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ CSV reader Ñ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ĞµĞ¼
            reader = csv.reader(infile, delimiter=delimiter, quoting=csv.QUOTE_MINIMAL)

            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ CSV writer Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑĞºÑ€Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
            writer = csv.writer(outfile, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)
            bad_writer = csv.writer(badfile, delimiter=export_delimiter, quoting=csv.QUOTE_ALL)

            # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ² bad Ñ„Ğ°Ğ¹Ğ» Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº
            bad_header = ['ĞĞ¾Ğ¼ĞµÑ€_ÑÑ‚Ñ€Ğ¾ĞºĞ¸', 'Ğ¢Ğ¸Ğ¿_Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸', 'ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ_Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸', 'Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ_ÑÑ‚Ñ€Ğ¾ĞºĞ¸']
            bad_writer.writerow(bad_header)

            # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
            try:
                header = next(reader)
                writer.writerow(header)
                header_cols = len(header)
                if expected_columns is None:
                    expected_columns_local = header_cols
                else:
                    expected_columns_local = expected_columns
                logger.info(f"ğŸ“‹ Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {header_cols} ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ²; Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ expected_columns={expected_columns_local}")
                logger.info(f"ğŸ”§ ĞĞ¾Ğ²Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ: {repr(export_delimiter)}")
            except StopIteration:
                logger.error("âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¸Ğ»Ğ¸ Ğ½Ğµ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº")
                return

            # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾ Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒÑ ÑĞºĞ»ĞµĞ¹ĞºĞ¸ Ğ´Ğ²ÑƒÑ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº
            import io as _io

            def _parse_row(text: str):
                try:
                    return next(csv.reader(_io.StringIO(text), delimiter=delimiter, quoting=csv.QUOTE_MINIMAL))
                except StopIteration:
                    return []
                except Exception:
                    return None

            phys_line_no = 2
            buffered_line = None
            while True:
                try:
                    if buffered_line is not None:
                        cur_line = buffered_line
                        buffered_line = None
                        from_buffer = True
                    else:
                        cur_line = infile.readline()
                        from_buffer = False
                    if not cur_line:
                        break

                    row = _parse_row(cur_line)
                    if row is not None and len(row) == expected_columns_local:
                        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° â€” ÑÑ€Ğ°Ğ·Ñƒ Ğ¿Ğ¸ÑˆĞµĞ¼
                        writer.writerow(row)
                        valid_count += 1
                        if valid_count % batch_size == 0:
                            logger.info(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº: {valid_count}")
                        phys_line_no += 1
                        continue

                    # ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ°Ñ â€” Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ÑĞºĞ»ĞµĞ¸Ñ‚ÑŒ Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¾Ğ¹
                    next_line = infile.readline()
                    if next_line:
                        combined = cur_line.rstrip('\r\n') + next_line.lstrip('\r\n')
                        combined_row = _parse_row(combined)
                        if combined_row is not None and len(combined_row) == expected_columns_local:
                            writer.writerow(combined_row)
                            valid_count += 1
                            if valid_count % batch_size == 0:
                                logger.info(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº: {valid_count}")
                            # Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ğ»Ğ¸ Ğ´Ğ²Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
                            phys_line_no += 2
                        else:
                            # Ğ¡ĞºĞ»ĞµĞ¹ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ»Ğ° â€” Ğ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ² bad Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ,
                            # ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ Ğ²ĞµÑ€Ğ½Ñ‘Ğ¼ Ğ² Ğ±ÑƒÑ„ĞµÑ€ Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¾ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
                            bad_len = (len(row) if row is not None else 'â€”')
                            content = cur_line.rstrip('\r\n')
                            if content.strip() == "":
                                desc = "ĞŸÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°"
                            else:
                                desc = (
                                    f"ĞĞµĞ²ĞµÑ€Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ²: {bad_len} Ğ²Ğ¼ĞµÑÑ‚Ğ¾ {expected_columns_local}"
                                    if isinstance(bad_len, int) else f"ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° (Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ»Ğ¾ÑÑŒ {expected_columns_local} ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ²)"
                                )
                            bad_writer.writerow([phys_line_no, "ĞÑˆĞ¸Ğ±ĞºĞ°_ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹", desc, content])
                            # Ğ’ Ñ„Ğ°Ğ¹Ğ» ÑÑ‹Ñ€Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¸ÑˆĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
                            badraw.write(cur_line)
                            bad_count += 1
                            if bad_count % 1000 == 0:
                                logger.warning(f"âš ï¸ ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº: {bad_count}")
                            phys_line_no += 1
                            buffered_line = next_line
                    else:
                        # Ğ½ĞµÑ‚ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ â€” Ñ„Ğ¸ĞºÑĞ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ ĞºĞ°Ğº Ğ±Ğ¸Ñ‚ÑƒÑ
                        content = cur_line.rstrip('\r\n')
                        if content.strip() == "":
                            desc = "ĞŸÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°"
                        else:
                            bad_len = (len(row) if row is not None else 'â€”')
                            desc = (
                                f"ĞĞµĞ²ĞµÑ€Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ²: {bad_len} Ğ²Ğ¼ĞµÑÑ‚Ğ¾ {expected_columns_local}"
                                if isinstance(bad_len, int) else f"ĞĞµĞ²ĞµÑ€Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° (Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ»Ğ¾ÑÑŒ {expected_columns_local} ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ²)"
                            )
                        bad_writer.writerow([phys_line_no, "ĞÑˆĞ¸Ğ±ĞºĞ°_ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹", desc, content])
                        # Ğ’ Ñ„Ğ°Ğ¹Ğ» ÑÑ‹Ñ€Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¸ÑˆĞµĞ¼ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹
                        badraw.write(cur_line)
                        bad_count += 1
                        if bad_count % 1000 == 0:
                            logger.warning(f"âš ï¸ ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº: {bad_count}")
                        phys_line_no += 1

                except Exception as e:
                    # ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ
                    error_desc = f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {str(e)[:100]}"
                    bad_writer.writerow([phys_line_no, "ĞÑˆĞ¸Ğ±ĞºĞ°_Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸", error_desc, (cur_line.rstrip('\r\n') if 'cur_line' in locals() else '')])
                    # Ğ’ Ñ„Ğ°Ğ¹Ğ» ÑÑ‹Ñ€Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ¿Ğ¸ÑˆĞµĞ¼ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ, ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ° ĞµÑÑ‚ÑŒ
                    if 'cur_line' in locals():
                        badraw.write(cur_line)
                    bad_count += 1
                    if bad_count % 1000 == 0:
                        logger.warning(f"âš ï¸ ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº: {bad_count}")
                    phys_line_no += 1

    except Exception as e:
        logger.error(f"âŒ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        raise

    logger.info(f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ…: {valid_count}, ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ…: {bad_count}")
    return valid_count, bad_count


def main():
    parser = argparse.ArgumentParser(description='ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ñ‹Ğ¹ CSV Ğ¿Ğ°Ñ€ÑĞµÑ€ Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ Ñ€ĞµĞ´ĞºĞ¸Ğ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ĞµĞ¼')
    parser.add_argument('input_path', help='ĞŸÑƒÑ‚ÑŒ Ğº Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ CSV Ñ„Ğ°Ğ¹Ğ»Ñƒ')
    parser.add_argument('output_path', help='ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ CSV')
    parser.add_argument('bad_path', help='ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº')
    parser.add_argument('--encoding', help='ĞšĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)')
    parser.add_argument('--delimiter', help='Ğ Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ CSV (Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)')
    parser.add_argument('--export_delimiter', default='~', help='Ğ Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ: ~)')
    parser.add_argument('--sample_size', type=int, default=10000,
                        help='Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸')
    parser.add_argument('--batch_size', type=int, default=10000,
                        help='Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°')

    args = parser.parse_args()

    input_path = Path(args.input_path)
    output_path = Path(args.output_path)
    bad_path = Path(args.bad_path)

    if not input_path.exists():
        logger.error(f"âŒ Ğ’Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {input_path}")
        return

    try:
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ„Ğ°Ğ¹Ğ»Ğ°
        encoding = args.encoding or detect_encoding(input_path, args.sample_size)
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ 10000 ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼ Ñ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ¾Ğ¼ >1 ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°
        delim, header_cols, modal_cols, total_rows, modal_share = analyze_csv_stats(
            input_path, encoding, max_lines=10000, provided_delimiter=args.delimiter
        )
        export_delimiter = args.export_delimiter

        logger.info(f"ğŸ” ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹: encoding={encoding}, Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ={repr(delim)}")
        logger.info(f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ {total_rows} ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼: header_cols={header_cols}, modal_cols={modal_cols}, modal_share={modal_share:.3f}")
        logger.info(f"ğŸ”§ Ğ’Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ: {repr(export_delimiter)}")
        logger.info(f"ğŸ“ Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ°: {input_path.stat().st_size / (1024 * 1024):.1f} MB")

        # ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ 90%: ĞµÑĞ»Ğ¸ >= 0.9 ÑÑ‚Ñ€Ğ¾Ğº ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ modal_cols, Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ±ĞµĞ· Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
        expected_columns = modal_cols if modal_share >= 0.9 else header_cols
        if header_cols != modal_cols and modal_share < 0.9:
            logger.warning(
                f"âš ï¸ Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº: {header_cols} ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº, ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸: {modal_cols} (Ğ´Ğ¾Ğ»Ñ {modal_share:.2%}). ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ñ expected_columns={expected_columns}."
            )

        # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ CSV
        valid_count, bad_count = process_csv_streaming(
            input_path, output_path, bad_path, encoding, delim, export_delimiter, args.batch_size, expected_columns=expected_columns
        )

        # Ğ’Ñ‹Ğ²ĞµĞ´ĞµĞ¼ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ ÑĞ²Ğ¾Ğ´ĞºÑƒ Ğ² stdout Ğ² ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Ğ´Ğ»Ñ UI
        try:
            print(f"__SUMMARY__ VALID={valid_count} BAD={bad_count}")
        except Exception:
            pass
        logger.info("âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° CSV Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")

    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        raise


if __name__ == "__main__":
    main()
